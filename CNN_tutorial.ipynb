{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN_tutorial.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shayanshafquat/DeepLearning/blob/main/CNN_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21YXWLJsBFF7"
      },
      "source": [
        "In this exercise we will train a convolutional neural network to classify MNIST characters.\n",
        "\n",
        "First we make sure we have GPU. Go to Edit $\\rightarrow$ Notebook Settings $\\rightarrow$ Hardware Accelerator $\\rightarrow$ GPU.\n",
        "\n",
        "You may have to restart the Runtime. Go to Runtime $\\rightarrow$ Restart runtime.\n",
        "\n",
        "Now we need to maksure we are using tensorflow v2 and not 1. You will need to restart the runtime again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5ODG2syG_Up"
      },
      "source": [
        "# get packages\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBS1yUMVHQCE"
      },
      "source": [
        "Okay lets download a dataset. In the tensorflow_datasets package we have access to many well known machine learning datasets. See  \n",
        "https://www.tensorflow.org/datasets/catalog/overview  \n",
        "for the full list. Here we will download the MNIST dataset which contains images of handwritten numbers 0-9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RrIvk3urxQY"
      },
      "source": [
        "ds = tfds.load(name=\"mnist\", as_supervised = True) #get mnist dataset\n",
        "train, test = ds[\"train\"], ds[\"test\"] #split train test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4JhzJtaHNnr"
      },
      "source": [
        "The data are already in test and train sets and we can see how much data is in each. We won't necessarily use all of this data later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aRnYUB1V4lr"
      },
      "source": [
        "ntrain = len([image[0] for image in train])\n",
        "ntest = len([image[0] for image in test])\n",
        "\n",
        "print('Train sample: ', ntrain)\n",
        "print('Test sample: ', ntest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y1fLoYoIPJ4"
      },
      "source": [
        "Let's take the first image from the train dataset and visualise it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEU3HcTh0NbM"
      },
      "source": [
        "# take 1 image from train and convert to float64 and values 0-1\n",
        "data1 = train.map(\n",
        "    lambda image, label: (tf.image.convert_image_dtype(image, tf.float64), label)\n",
        ").take(1)\n",
        "\n",
        "#get first image data and label and plot it\n",
        "features, labels = iter(data1).next()\n",
        "print('image 1 shape: ', np.shape(features));\n",
        "# plt.imshow(features[:,:,0], cmap='gray_r');\n",
        "plt.imshow(features[:,:,0], cmap='viridis');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szJwaVTyIl0c"
      },
      "source": [
        "You should see that we have an 28x28 grayscale image (1 channel) of the handwritten digit 8.\n",
        "\n",
        "To give you a feel for what the convolutional layer does, we are now going to apply filters to this image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyLcJFYtJfAF"
      },
      "source": [
        "Firstly we will apply a horizontal filter  \n",
        "\\begin{bmatrix}\n",
        "1 & 1 & 1 \\\\\n",
        "0 & 0 & 0 \\\\\n",
        "-1 & -1 & -1\n",
        "\\end{bmatrix}\n",
        "\n",
        "This filter enhances the horizontal features of the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owjthOwpCJDr"
      },
      "source": [
        "hor_filter = [[1,1,1],[0,0,0],[-1,-1,-1]]\n",
        "\n",
        "#2D convolution\n",
        "output = tf.nn.conv2d(\n",
        "      input=np.reshape(features, [1,28,28,1]), #batch, height, width, depth\n",
        "      filters=np.reshape(hor_filter, [3,3,1,1]), #height, width, in_channels, out_channels\n",
        "      strides=[1,1,1,1],\n",
        "      padding=\"VALID\")\n",
        "print('image shape: ', np.shape(output));\n",
        "plt.imshow(output[0,:,:,0], cmap='gray');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHHzkCI7KDM9"
      },
      "source": [
        "The filter has extracted the features of horizontal edges in the image. Note that the image size has shrunk from 28x28 to 26x26.\n",
        "\n",
        "Now lets try a vertical filter  \n",
        "\\begin{bmatrix}\n",
        "1 & 0 & -1 \\\\\n",
        "1 & 0 & -1 \\\\\n",
        "1 & 0 & -1\n",
        "\\end{bmatrix}\n",
        "\n",
        "You should find that this filter extracts the vertical edges of the image. Try it yourself:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya0jt-bFFvab"
      },
      "source": [
        "ver_filter = [[1,0,-1],[1,0,-1],[1,0,-1]] #fill this in with the values of the vertical filter above\n",
        "\n",
        "output = tf.nn.conv2d( #Look to the previous code chunk with the vertical filter to fill in this function\n",
        "      input=np.reshape(output, [1,26,26,1]),\n",
        "      filters=np.reshape(ver_filter, [3,3,1,1]),\n",
        "      strides=[1,1,1,1],\n",
        "      padding=\"VALID\")\n",
        "print('image shape: ', np.shape(output));\n",
        "plt.imshow(output[0,:,:,0], cmap='gray');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fusvio_6cVz2"
      },
      "source": [
        "# Convolutional layer\n",
        "Now your task is to write your own function that takes an image, and a kernel to perform the convolution operation. Assume stride 1 and no padding.\n",
        "\n",
        "First do it with just one kernel and 1 channel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3OV4QLNBHz4"
      },
      "source": [
        "# It will first help to write a function that unrolls the kernel like shown in the course notes and lecture.\n",
        "# It should take a kernel matrix F of size [ky,kx] and return a matrix of size [ox*oy,nx*ny ] where nx,ny\n",
        "# is the dimension of the input after padding (in_pad) and ox, oy are the output dimensions.\n",
        "# Note that there are many variations to writing a convolution function, so feel free to just code your way\n",
        "# and ignore pointers if you wish\n",
        "\n",
        "def unroll(F, ky, kx, ny, nx, oy, ox, stride):\n",
        "    #calculate the output size of the unrolled matrix\n",
        "    ux = ox*oy\n",
        "    uy = nx*ny\n",
        "\n",
        "    #pad the filter first using the function tf.pad so that its the same size as the image\n",
        "    Fpadded = tf.pad(F, [[0, (nx-kx)],[0, (ny-ky)]] )\n",
        "\n",
        "    #flatten the filter into a vector of size uy\n",
        "    Fflat = tf.reshape(Fpadded,[uy])\n",
        "\n",
        "    #unroll the filter\n",
        "    unrolledF = []\n",
        "    for iy in range(oy):\n",
        "        for ix in range(ox):\n",
        "            unrolled = tf.roll(Fflat, shift=(ix*stride+iy*(stride*nx)), axis=0) #shifts the flattened filters for each row of the unrolled filter\n",
        "            unrolledF.append(unrolled)\n",
        "    out = tf.stack(unrolledF)\n",
        "\n",
        "    out = tf.reshape(out, [ux,uy])    #reshape to output size\n",
        "    return(out)\n",
        "\n",
        "\n",
        "# The convolutional layer should take an image of size [iy,ix], filter kernel of size [kx,ky],\n",
        "#bias of size [1], padding of size [1] and stride of size 1\n",
        "\n",
        "def convolve2d(infeat, kernel, bias, padding, stride):\n",
        "    # get the shape of the kernel and input using the function get_shape()\n",
        "    ky, kx = kernel.get_shape()\n",
        "    iy, ix = infeat.get_shape()\n",
        "\n",
        "    #add padding to the input and get the shape of the result\n",
        "    in_pad = tf.pad(infeat, [[padding, padding],[padding, padding]] )\n",
        "    ny, nx = in_pad.get_shape()\n",
        "\n",
        "    # Calculate the output size\n",
        "    ox = nx - kx // stride + 1\n",
        "    oy = ny - ky // stride + 1\n",
        "\n",
        "    #unroll the kernel\n",
        "    unrollF = unroll(kernel, ky, kx, ny, nx,oy,ox, stride=stride)\n",
        "\n",
        "    # flatten the padded input\n",
        "    unrollI = tf.reshape(in_pad, [nx*ny])\n",
        "\n",
        "    #multiply the unrolled matrices together\n",
        "    convO = tf.tensordot(unrollF, unrollI, axes=1)\n",
        "\n",
        "    #reshape to outout size and add bias term\n",
        "    conv_reshaped = tf.reshape(convO, [ox,oy])\n",
        "    outfeat = conv_reshaped + bias\n",
        "\n",
        "    return outfeat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbRweFYcBHz7"
      },
      "source": [
        "To check you have succeeded, we'll apply it to a test, if the printed difference is 0, you can move forward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tEfVx7uBHz7"
      },
      "source": [
        "f1 = [[2,1],[2,1]]\n",
        "a = tf.constant([[1,2,3],[1,2,3],[1,2,3]], dtype=tf.float64)\n",
        "out = convolve2d(a, tf.constant(f1, dtype=tf.float64), bias=0, padding=1, stride=1)\n",
        "dif = [[ 1.,  4.,  7.,  6.],[ 2.,  8., 14., 12.],[ 2.,  8., 14., 12.], [ 1.,  4.,  7.,  6.]]\n",
        "print('Difference from truth: '); tf.print(tf.reduce_sum(dif-out))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STcD_0jOBHz-"
      },
      "source": [
        "Now we want to generalise to 3 channels. Remember the number of channels in the image must equal the number of channels in the kernel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2fXoWiABHz_"
      },
      "source": [
        "# The output of the unrolled kernel should be still be 2D\n",
        "def unroll(F,  ky, kx, kz, ny, nx, nz, oy, ox, stride):\n",
        "    uy = ox*oy\n",
        "    ux = nx*ny*nz\n",
        "\n",
        "    #pad and flatten the filter, dimensions should be the [nx*ny*nz]\n",
        "    Fpadded = tf.pad(F, [[0, (ny-ky)],[0, (nx-kx)],[0,0]])\n",
        "    Fflat = tf.reshape(Fpadded,[nz*ny*nx])\n",
        "    unrolledF = []\n",
        "    for iy in range(oy):\n",
        "        for ix in range(ox):\n",
        "            unroll = tf.roll(Fflat, shift=(ix*(stride*nz)+iy*(stride*nx*nz)), axis=0)\n",
        "            unrolledF.append(unroll)\n",
        "    out=tf.stack(unrolledF)\n",
        "    out=tf.reshape(out, [uy,ux])\n",
        "\n",
        "    return(out)\n",
        "\n",
        "\n",
        "#here beware that although we have multi channels, the bias remains as 1 per filter, not per filter channel\n",
        "def convolve2d(infeat, kernel, bias, padding, stride):\n",
        "    ky, kx, kz = kernel.get_shape()\n",
        "    iy, ix, iz = infeat.get_shape()\n",
        "\n",
        "    #pad input\n",
        "    in_pad = tf.pad(infeat, [[padding,padding],[padding,padding],[0,0]])\n",
        "    ny, nx,nz = in_pad.get_shape()\n",
        "\n",
        "    ox = (nx - kx) // stride + 1 # output size\n",
        "    oy = (ny - ky) // stride + 1\n",
        "\n",
        "    unrollI = tf.reshape(in_pad, [ny*nx*nz])\n",
        "    unrollF = unroll(kernel,ky, kx, kz, ny, nx,nz,oy,ox, stride=stride)\n",
        "    convO = tf.tensordot(unrollF, unrollI, axes=1) #convolution\n",
        "\n",
        "    conv_reshaped = tf.reshape(convO, [oy,ox]) #reshape\n",
        "\n",
        "    outfeat = conv_reshaped + bias\n",
        "\n",
        "    return outfeat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYM9PnS-BH0C"
      },
      "source": [
        "Lets check you're correct with an example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iACyNQfBH0D"
      },
      "source": [
        "# 3 channel input\n",
        "a = tf.constant([[[5,2,3],[1,2,1],[1,2,3],[1,2,3]],\n",
        "                 [[3,2,3],[1,0,3],[1,2,1],[0,0,1]],\n",
        "                 [[1,1,1],[1,2,3],[0,2,3],[1,2,1]],\n",
        "                 [[1,0,3],[0,2,0],[1,2,3],[1,2,3]]], dtype=tf.float64)\n",
        "\n",
        "# 3 channel kernel\n",
        "f1 = [[2,1],[2,1]]\n",
        "f2 = [[3,1],[3,3]]\n",
        "f3 = [[3,2],[2,3]]\n",
        "f=np.dstack((f1,f2,f3))\n",
        "\n",
        "out = convolve2d(a, tf.constant(f, dtype=tf.float64), 0, 1, 1)\n",
        "dif =[[20., 32., 26., 30., 14.],[31., 58., 38., 39., 19.],[18., 51., 45., 35., 13.],[14., 31., 47., 50., 25.], [ 7., 13., 15., 26., 17.]]\n",
        "print('Difference from truth: '); tf.print(tf.reduce_sum(dif-out))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBBRDXmLBH0H"
      },
      "source": [
        "Now lets generalise to multiple multichannel-filters where kn corresponds to each of the filters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPOVw-0aBH0I"
      },
      "source": [
        "#The output of the unrolled matrix should be [kn,uy,ux]\n",
        "def unroll(F,  kn, ky, kx, kz, ny, nx, nz, oy, ox, stride):\n",
        "    #define output size of unrolled matrix\n",
        "    uy =\n",
        "    ux =\n",
        "\n",
        "    #pad and flatten the filter. The padded filter should have dimensions [filters, height, width, depth]\n",
        "    Fpadded =\n",
        "    Fflat =  #dimensions should be the [kn, nx*ny*nz]\n",
        "\n",
        "    #unroll the matrix\n",
        "    unrolledF = []\n",
        "    for iy in range(oy):\n",
        "        for ix in range(ox):\n",
        "            unroll =  #since we have added multifilters the axis of roll will have changed, but the shift will be the same as the previous code chunk\n",
        "            unrolledF.append(unroll)\n",
        "\n",
        "    #stack again beware of the axis you want to stack\n",
        "    out=\n",
        "\n",
        "    #reshape to size [kn,uy,ux]\n",
        "    out=\n",
        "\n",
        "    return(out)\n",
        "\n",
        "\n",
        "def convolve2d(infeat, kernel, bias, padding, stride):\n",
        "    kn, ky, kx, kz =\n",
        "    iy, ix, iz =\n",
        "\n",
        "    #pad input and get size\n",
        "    in_pad =\n",
        "    ny, nx,nz =\n",
        "\n",
        "    #calculate outputsize\n",
        "    ox =\n",
        "    oy =\n",
        "\n",
        "    #unroll input to size ny*nx*nz\n",
        "    unrollI =\n",
        "    #unroll kernel\n",
        "    unrollF = unroll(kernel, kn, ky, kx, kz, ny, nx,nz,oy,ox, stride=stride)\n",
        "\n",
        "    #multiply the unrolled matrices and dont forget to add the bias\n",
        "\n",
        "    convO = tf.tensordot(unrollF, unrollI, axes=1) #convolution\n",
        "    conv_reshaped = tf.reshape(tf.transpose(convO), [oy,ox,kn]) #reshape\n",
        "\n",
        "    outfeat = conv_reshaped + bias\n",
        "\n",
        "    return outfeat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI0jHAsXyTB5"
      },
      "source": [
        "Check it works, the output of the next chunk should be 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s26Wr_XqBH0M"
      },
      "source": [
        "# 4x3 channel kernels\n",
        "f1 = [[2,1],[2,1]]\n",
        "f2 = [[3,1],[3,3]]\n",
        "f3 = [[3,2],[2,3]]\n",
        "k1 = np.dstack((f1,f1,f1))\n",
        "k2 = np.dstack((f2,f2,f2))\n",
        "k3 = np.dstack((f3,f3,f3))\n",
        "k4 = np.dstack((f1,f2,f3))\n",
        "\n",
        "out = convolve2d(a, tf.constant([k1,k2,k3,k4], dtype=tf.float64), 0, 1, 1)\n",
        "\n",
        "dif =[[[10., 30., 30., 20.],\n",
        "        [24., 42., 32., 32.],\n",
        "        [14., 30., 26., 26.],\n",
        "        [18., 36., 30., 30.],\n",
        "        [12., 18., 12., 14.]],\n",
        "\n",
        "       [[18., 34., 44., 31.],\n",
        "        [44., 70., 66., 58.],\n",
        "        [26., 42., 44., 38.],\n",
        "        [27., 39., 41., 39.],\n",
        "        [14., 21., 20., 19.]],\n",
        "\n",
        "       [[11., 17., 25., 18.],\n",
        "        [32., 55., 56., 51.],\n",
        "        [29., 49., 47., 45.],\n",
        "        [23., 40., 36., 35.],\n",
        "        [10., 15., 11., 13.]],\n",
        "\n",
        "       [[ 7., 15., 18., 14.],\n",
        "        [22., 33., 35., 31.],\n",
        "        [27., 47., 50., 47.],\n",
        "        [32., 55., 53., 50.],\n",
        "        [20., 30., 24., 25.]],\n",
        "\n",
        "       [[ 4.,  4.,  8.,  7.],\n",
        "        [10., 14., 16., 13.],\n",
        "        [10., 12., 18., 15.],\n",
        "        [18., 24., 30., 26.],\n",
        "        [12., 18., 18., 17.]]]\n",
        "\n",
        "print('Difference from truth: '); tf.print(tf.reduce_sum(dif-out))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgnokhZYycY8"
      },
      "source": [
        "Now lets allow for batches of images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtY_xl5XyfyP"
      },
      "source": [
        "def unroll(F,  kn, ky, kx, kz, nn, ny, nx, nz, oy, ox, stride):\n",
        "    uy = ox*oy\n",
        "    ux = nx*ny*nz\n",
        "\n",
        "    #pad and flatten the filter\n",
        "    Fpadded = tf.pad(F, [[0,0],[0, (ny-ky)],[0, (nx-kx)],[0,0]])\n",
        "    Fflat = tf.reshape(Fpadded,[kn, nz*ny*nx])\n",
        "    unrolledF = []\n",
        "    for iy in range(oy):\n",
        "        for ix in range(ox):\n",
        "            unroll = tf.roll(Fflat, shift=(ix*(stride*nz)+iy*(stride*nx*nz)), axis=1)\n",
        "            unrolledF.append(unroll)\n",
        "    out=tf.stack(unrolledF, axis=1)\n",
        "    out=tf.reshape(out, [kn, uy,ux])\n",
        "\n",
        "    return(out)\n",
        "\n",
        "def convolve2d(infeat, kernel, bias, padding, stride):\n",
        "    kn, ky, kx, kz = kernel.get_shape()\n",
        "    inn,iy, ix, iz = infeat.get_shape()\n",
        "\n",
        "    #pad input, now we have 4 dimensions [batch, width, height, depth] - what dimensions need padding?\n",
        "    in_pad =\n",
        "    #get new shape\n",
        "    nn, ny, nx,nz =\n",
        "\n",
        "    ox = (nx - kx) // stride + 1 # output size\n",
        "    oy = (ny - ky) // stride + 1\n",
        "\n",
        "    #reshape padded input to size of [batches, width*height*depth]\n",
        "    unrollI =\n",
        "    unrollF = unroll(kernel, kn, ky, kx, kz, nn, ny, nx,nz,oy,ox, stride=stride)\n",
        "\n",
        "    convO = tf.tensordot(unrollF, unrollI, axes=[[2],[1]]) #convolution\n",
        "    conv_reshaped = tf.reshape(tf.transpose(convO), [nn,oy,ox,kn]) #reshape\n",
        "    outfeat = conv_reshaped + bias\n",
        "\n",
        "    return outfeat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMTsz0u1BH0U"
      },
      "source": [
        "Check your functions work by applying the convolution layer with the vertical filter on the first image on MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Kl7D-YvBH0V"
      },
      "source": [
        "x = tf.constant(np.reshape(features[:,:,0],(1,28,28,1)))\n",
        "b = tf.constant(np.reshape(ver_filter, (1,3,3,1)), dtype=tf.float64)\n",
        "np.shape(b)\n",
        "out=convolve2d(x,b,0, padding=0, stride=1);\n",
        "out.get_shape()\n",
        "plt.imshow(out[0,:,:,0], cmap='gray');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5pVRsQTcj1t"
      },
      "source": [
        "Compare the convolution with the correct answer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsheyY1nBH0Y"
      },
      "source": [
        "difs = out[0,:,:,0] - output[0,:,:,0]\n",
        "plt.imshow(difs, cmap='gray');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5XfhPmWBH0b"
      },
      "source": [
        "plt.hist(difs);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQR-PeKqBH0m"
      },
      "source": [
        "You might see some differences but these are due to rounding errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-__1MRJBH0n"
      },
      "source": [
        "# Activation Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6Sm9q5rBH0v"
      },
      "source": [
        "The convolution operation is linear. To make it non-linear we need to add an activation function. Here your task is to write a ReLU activation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Nc3CwScBH0w"
      },
      "source": [
        "def ReLU(infeat):\n",
        "    return\n",
        "\n",
        "relu0 = ReLU(out)\n",
        "plt.imshow(relu0[0,:,:,0]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DaKE5ulBH0y"
      },
      "source": [
        "Compare it to the built in function it should look like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxR8nlL3BH0z"
      },
      "source": [
        "true_relu0 = tf.nn.relu(out)\n",
        "plt.imshow(true_relu0[0,:,:,0]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egbO3wf1ctMs"
      },
      "source": [
        "# Pooling layer\n",
        "Write a function to do pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTgERMIGBH06"
      },
      "source": [
        "def pooling(infeat, ky, kx,kz, padding, stride, pooling_type):\n",
        "\n",
        "    #pad the input, again remember there are 4 dimensions - think which ones need padding\n",
        "    in_pad =\n",
        "\n",
        "    #get new shape of input\n",
        "    nn, ny, nx, nz =\n",
        "    kn = nn\n",
        "\n",
        "    #get output shapes\n",
        "\n",
        "    ox =\n",
        "    oy =\n",
        "    oz =\n",
        "\n",
        "    #unroll to get indices to pool\n",
        "    unrolledF = unroll(tf.ones([kn,ky,kx,kz]), kn, ky, kx, kz, nn, ny, nx, nz, oy, ox, stride)\n",
        "\n",
        "    #multiply unrolled kernel with input to get values to pool\n",
        "    flatin = tf.reshape(in_pad,[nn,nz*nx*ny])\n",
        "    tilein = tf.tile(flatin, [1,ox*oy])\n",
        "    test = tf.reshape(tilein, [nn, ox*oy, nz*nx*ny])\n",
        "    pools = tf.boolean_mask(test, unrolledF[:,:,:])\n",
        "    tileout = tf.reshape(pools, [nn,ox*oy,kx*ky,oz])\n",
        "\n",
        "    #apply max or mean pooling using tf.reduce_max and tf.reduce_mean on axis 2\n",
        "    if(pooling_type=='MAX'):\n",
        "        out =\n",
        "    elif(pooling_type=='AVG'):\n",
        "        out =\n",
        "    return tf.reshape(out, [nn,oy,ox,oz])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuthMAa4BH0_"
      },
      "source": [
        "Apply the pooling layer to the raw image with a 5x5 filter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MogBFj1BH1A"
      },
      "source": [
        "pooled = pooling(relu0,5,5,1,0,1, 'AVG')\n",
        "plt.imshow(pooled[0,:,:,0], cmap='gray');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQhJa0teBH1C"
      },
      "source": [
        "You should have got something like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxercJk3vBWE"
      },
      "source": [
        "n, y,x,z = np.shape(relu0)\n",
        "true_pooled = tf.nn.pool(\n",
        "    input = np.reshape(relu0, [1,y,x,1]),\n",
        "    window_shape = [5,5],\n",
        "    strides=[1,1],\n",
        "    pooling_type = 'AVG',\n",
        "    padding = 'VALID'\n",
        ")\n",
        "plt.imshow(true_pooled[0,:,:,0],cmap='gray');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9IEHp9FvFHf"
      },
      "source": [
        "How does Max pool and average pool compare?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK5jN6wgvP0f"
      },
      "source": [
        "pooled = pooling(relu0,5,5,1,0,1, 'MAX')\n",
        "plt.imshow(pooled[0,:,:,0], cmap='gray');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8bbc_nFvPdF"
      },
      "source": [
        "What happens when you apply the activation?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikiGyo4Mvh8-"
      },
      "source": [
        "relu1 = ReLU(pooled)\n",
        "plt.imshow(relu1[0,:,:,0], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO_cq1xpBH1R"
      },
      "source": [
        "# Fully connected layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zG3n-m1eBH1S"
      },
      "source": [
        "The fully connected layer, is a layer that has no shared weights. In this part you need to write a function for the fully connected layer. Remember here there is a bias for every filter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbnSs3aeBH1T"
      },
      "source": [
        "def fully_connected(infeat, kernel, bias):\n",
        "    #get input and kernel shapes\n",
        "    nn,ny, nx, nz =\n",
        "    kn, ky, kx, kz =\n",
        "\n",
        "    #reshape input and kernel to shape, they should both be 2D matrices\n",
        "    flatin =\n",
        "    flatk =\n",
        "\n",
        "    # apply matrix multiplication and bias. You may need to use tf.transpose to get the right shape. output size should be [nn,1,1,kn]\n",
        "    out =\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyUQ6ZVCBH1a"
      },
      "source": [
        "Now test the fully connected layer works"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLIoVFN3BH1a"
      },
      "source": [
        "kn = 2\n",
        "imn = 1\n",
        "k = np.random.randint(low=0, high=2,size=[kn,3,3,1])\n",
        "\n",
        "b = tf.zeros([imn,kn],dtype=tf.float64)\n",
        "\n",
        "im = np.random.randint(low=0, high=5,size=[imn,3,3,1])\n",
        "fully_connected(tf.constant(im,dtype=tf.float64),tf.constant(k,dtype=tf.float64), b )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96vsgjZQBH1d"
      },
      "source": [
        "Actually you should find that the fully connected layer is the same as the conv2D layer using a kernel size the same as the input size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaTWF9zsBH1e"
      },
      "source": [
        "convolve2d(tf.constant(im,dtype=tf.float64),tf.constant(k,dtype=tf.float64),0, padding=0, stride=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb1G09Z9BH1g"
      },
      "source": [
        "apply the fully connected layer we just created to the output of the ReLU activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCWLaQ4PBH1h"
      },
      "source": [
        "nn,ny,nx,nz = relu1.get_shape()\n",
        "outsz = 2\n",
        "\n",
        "#kernel size has dimensions [input width, input height,output size]\n",
        "ink = tf.random.normal([outsz, ny, nx, nz], dtype=tf.float64)\n",
        "\n",
        "#bias size has dimensions [output size]\n",
        "inb = tf.zeros([nn,outsz],dtype=tf.float64)\n",
        "\n",
        "outim = fully_connected(relu1, ink, inb)\n",
        "tf.print(outim);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0q1LL6fBH1k"
      },
      "source": [
        "after a fully connected layer you must add non-linearity via an activation function. Since its not yet the last layer we can add ReLU activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dXuZ1u8BH1k"
      },
      "source": [
        "relu2 = ReLU(outim)\n",
        "tf.print(relu2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGWTh_VcBH1t"
      },
      "source": [
        "# Softmax activation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl75Jb3wBH1u"
      },
      "source": [
        "For the last layer, you probably want to use softmax activation. So here you should write a function to do softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gndJazVFBH1u"
      },
      "source": [
        "def softmax(infeat):\n",
        "    innorm = #normalise the input values with the maximum to prevent blow up\n",
        "    inexp =\n",
        "    tot =  #normalisation factor\n",
        "\n",
        "    return inexp / tot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5l4uGzjBH1x"
      },
      "source": [
        "Add the final fully connected layer and softmax activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYV590i-BH1y"
      },
      "source": [
        "nn,ny,nx,nz= relu2.get_shape()\n",
        "outsz = 3\n",
        "\n",
        "#kernel size has dimensions [output size, input width, input height]\n",
        "ink = tf.random.normal([outsz,ny,nx,nz], dtype=tf.float64)\n",
        "\n",
        "#bias size has dimensions [output size, 1]\n",
        "inb = tf.zeros([nn,outsz],dtype=tf.float64)\n",
        "\n",
        "outim = fully_connected(relu2, ink, inb)\n",
        "out = softmax(outim)\n",
        "tf.print(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YyVVYyr13Kt"
      },
      "source": [
        "define a loss function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xmYhbl_BH2Z"
      },
      "source": [
        "def cross_entropy_loss(y, t):\n",
        "    return tf.reduce_mean(tf.losses.categorical_crossentropy( t,  y))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvkrl5x9BH20"
      },
      "source": [
        "# Build the neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKaqEoTQBH20"
      },
      "source": [
        "Now you have all the functions you need to build your neural network so first you need to set up all the variables and their dimensions. We are going to make a 4 layer network with CONV-RELU-MAXPOOL-CONV-RELU-MAXPOOL-FC-FC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7V_Rv4GBH21"
      },
      "source": [
        "# First initialise variables\n",
        "f1n, f1y, f1x, f1z = 10, 3, 3, 1\n",
        "W1 = tf.Variable(tf.random.normal([f1n, f1y, f1x, f1z], stddev=0.01, dtype=tf.float64 ), name='W1')\n",
        "b1 = tf.Variable(tf.zeros([f1n], dtype=tf.float64 ), name='b1')\n",
        "\n",
        "f2n, f2y, f2x, f2z = 10, 3, 3, 10\n",
        "W2 =\n",
        "b2 =\n",
        "\n",
        "f3n, f3y, f3x, f3z = 50, 20, 20, 10\n",
        "W3 =\n",
        "b3 =\n",
        "\n",
        "f4n, f4y, f4x, f4z =\n",
        "W4 =\n",
        "b4 ="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFV1AcQABH23"
      },
      "source": [
        "Next set up the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvjOqSMRBH24"
      },
      "source": [
        "def model( X ) :\n",
        "    X = tf.cast( X , dtype=tf.float64 )\n",
        "\n",
        "    #LAYER 1\n",
        "    conv1 = convolve2d(X, W1, b1, padding=0, stride=1);\n",
        "    conv1act = ReLU(conv1)\n",
        "    pool1 = pooling(conv1act, 3, 3, 10, 0, 1, 'MAX')\n",
        "\n",
        "    #LAYER 2\n",
        "    conv2 =\n",
        "    conv2act =\n",
        "    pool2 =\n",
        "\n",
        "    #LAYER 3\n",
        "    fc1 = fully_connected(pool2, W3, b3)\n",
        "    fc1act = ReLU(fc1) #out[1,1,50]\n",
        "\n",
        "    #LAYER 4\n",
        "    fc2 =\n",
        "    fc2act =\n",
        "\n",
        "    return(fc2act)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG4gyYApBH26"
      },
      "source": [
        "Train the model on MNIST training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F16tYf9VBH26"
      },
      "source": [
        "LR = 0.001 #learning rate\n",
        "optimizer = tf.optimizers.Adam(LR) #adam optimiser\n",
        "\n",
        "def train_step( model, X , Y ):\n",
        "    with tf.GradientTape() as tape:\n",
        "        current_loss = cross_entropy_loss( model( X ), Y)\n",
        "    grads = tape.gradient( current_loss , [W1,b1,W2,b2,W3,b3,W4,b4] )\n",
        "    optimizer.apply_gradients( zip( grads , [W1,b1,W2,b2,W3,b3,W4,b4]) ) #update gradients\n",
        "\n",
        "    return(current_loss)\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "dfkPOYz9BH2-"
      },
      "source": [
        "dataset = train.map(\n",
        "    lambda image, label: (tf.image.convert_image_dtype(image, tf.float64), label)\n",
        ").take(500 #train on 500 images\n",
        ").batch(10) #in batches of 10\n",
        "\n",
        "nepoch = 200\n",
        "\n",
        "for epoch in range(nepoch):\n",
        "    for features in dataset:\n",
        "        image, label = features[0] , features[1]\n",
        "        loss = train_step( model , image , tf.one_hot( label , depth=10 ) ) #run training, with labels reformated to size [batch, nclass]\n",
        "    print('epoch: ',epoch, ', loss:', loss)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9wDc1cbBH3A"
      },
      "source": [
        "Apply on the model to the MNIST test data and compare with truth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMvpyLKUBH3B"
      },
      "source": [
        "testset = test.map(\n",
        "    lambda image, label: (tf.image.convert_image_dtype(image, tf.float64), label)\n",
        ").take(20\n",
        ")\n",
        "\n",
        "for features in testset:\n",
        "    image, label = features[0] , features[1]\n",
        "    pred = model(image)\n",
        "    pred_label = tf.argmax(pred, axis=2)\n",
        "    tf.print('predicted: ', pred_label, '  - true: ', label)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwJk5OBfBH3D"
      },
      "source": [
        "# Additional work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI-nEmDFBH3D"
      },
      "source": [
        "- You can log and plot the training loss to see how well the network is doing during training.\n",
        "\n",
        "- Try to see if you can improve the performance of the network, these can be done by introducing batches for training, augmentations etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D9xhoSJQBtM"
      },
      "source": [
        "# Extra reading\n",
        "\n",
        "- deconvolution layers:  \n",
        "https://medium.com/activating-robotic-minds/up-sampling-with-transposed-convolution-9ae4f2df52d0\n",
        "\n",
        "- A guide to convolutional arithmetic in deep learning, Dumoulin & Visin\n",
        ":  \n",
        "https://arxiv.org/abs/1603.07285  \n",
        "\n",
        "- Fully convolutional networks for semantic segmentation, Long et al:\n",
        "https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf\n",
        "\n",
        "- Deconvolution & checkerboard artefacts, Odena et al:\n",
        "https://distill.pub/2016/deconv-checkerboard/\n"
      ]
    }
  ]
}